{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.1 Composition of poses and landmarks\n",
    "\n",
    "## Theoretical background\n",
    "\n",
    "The purpose of this exercise is to familiarise ourselves with the process of observing landmarks from robot poses and the transformations needed to make use of these observations.\n",
    "\n",
    "Some concepts necessary:\n",
    "\n",
    "- **World frame**: $x, y$ coordinates from a selected point of reference $(0, 0)$. We use to keep track of the robots pose, and within the map.\n",
    "- **Observation**: Information from the real world provided by a sensor, from the point of view (*pov*) of a certain robot.\n",
    "- **Range-bearing sensor**: Sensor model being used in this lesson. They detect how far is an object $(d)$ and its orientation relative to the robot's $(\\theta)$.\n",
    "\n",
    "The main tools for that are:\n",
    "\n",
    "- the composition of two poses and the composition of a pose and a landmark.\n",
    "- the propagation of uncertainty through the Jacobians of these compositions.\n",
    "\n",
    "We will address several problems of incremental complexity. The following figures will help you to follow the exercise.\n",
    "\n",
    "<center>\n",
    "<img src=\"images/fig4-1-1.png\" width=\"900\">\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib notebook\n",
    "%matplotlib inline\n",
    "\n",
    "# IMPORTS\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "from utils.PlotEllipse import PlotEllipse\n",
    "from utils.DrawRobot import DrawRobot\n",
    "from utils.tcomp import tcomp\n",
    "from utils.tinv import tinv, jac_tinv1 as jac_tinv\n",
    "from utils.Jacobians import J1, J2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Let‚Äôs consider a robot R1 at a perfectly known pose $p_1 = [1, 2, 0.5]^T$ which observes\n",
    " a landmark m with a range-bearing (polar) sensor affected by a zero-mean\n",
    " Gaussian error with covariance $W_{1p} = diag\\left([0.25, 0.04]\\right)$. The sensor provides the\n",
    " measurement $z_{1p} = [4m., 0.7rad.]^T$. Compute the Gaussian probability distribution\n",
    " (mean and covariance) of the landmark in the world frame (the same as the robot)\n",
    " and plot its corresponding ellipse (in magenta, $\\sigma=1$).\n",
    " \n",
    " **Hint**: Prior to propagate the measurement uncertainty, we need to compute the\n",
    " covariance of the observation in the Cartesian robot R1 frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_world_frame(p1_w, Qp1_w, z1_p_r, W1):\n",
    "    \"\"\" Covert the observation z1_p_r to the world frame\n",
    "    \n",
    "        Args:\n",
    "            p1_w: Pose of the robot(in world frame)\n",
    "            Qp1_w: Covariance of the robot\n",
    "            z1_p_r: Observation to a landmark(polar coordinates) from robots perspective\n",
    "            W1: Covariance of the sensor\n",
    "    \n",
    "        Returns:\n",
    "            z1_w: Pose of landmark in the world frame\n",
    "            Qz1: Covariance associated to z1_w\n",
    "    \"\"\"\n",
    "    # TODO: Implement function\n",
    "    raise NotImplementedError\n",
    "    \n",
    "    return z1_w, Qz1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MATPLOTLIB\n",
    "fig, ax = plt.subplots()\n",
    "plt.xlim([-.5, 10])\n",
    "plt.ylim([-.5, 10])\n",
    "plt.grid()\n",
    "plt.tight_layout()\n",
    "\n",
    "p1_w = np.vstack([1, 2, 0.5])\n",
    "Qp1_w = np.zeros((3, 3))\n",
    "\n",
    "z1_p_r = np.vstack([4., .7])\n",
    "W1 = np.diag([0.25, 0.04])\n",
    "\n",
    "z1_w, Qz1 = to_world_frame(p1_w, Qp1_w, z1_p_r, W1)\n",
    "\n",
    "DrawRobot(fig, ax, p1_w, label='R1', color='blue')\n",
    "    \n",
    "ax.plot(z1_w[0, 0], z1_w[1, 0], 'o', label='Z1', color='green')\n",
    "PlotEllipse(fig, ax, z1_w, Qz1, color='green')\n",
    "\n",
    "plt.legend()\n",
    "print('----\\tExercise 4.1.1\\t----\\n'+\n",
    "      'z1_w = {}\\'\\n'.format(z1_w.flatten())\n",
    "      + 'Wz1_w = \\n{}\\n'.format(Qz1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expected results for demo:\n",
    "\n",
    "```\n",
    "---- Exercise 4.1.1 ----\n",
    "z1_w = [2.44943102 5.72815634]'\n",
    "Wz1_w = \n",
    "[[ 0.58879177 -0.13171532]\n",
    " [-0.13171532  0.30120823]]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Now, let‚Äôs assume that the robot pose is not known, but a RV that follows a\n",
    "Gaussian probability distribution: $p_1 \\sim N([1, 2, 0.5]^T, \\Sigma_1)$ with $\\Sigma_1 = diag([0.08,0.6,\n",
    "0.02 ])$.\n",
    "\n",
    "    1. Compute the covariance matrix $\\Sigma_{m1}$ of the landmark in the world frame and\n",
    "     plot it as an ellipse centered at the mean $m_1$ (in blue, $sigma= 1$). Plot also\n",
    "     the covariance of the robot pose (in blue, $sigma= 1$).\n",
    "     \n",
    "    2. Compare the covariance with that obtained in the previous case. Is it\n",
    "     bigger? Is it bigger than that of the robot? Why?  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MATPLOTLIB\n",
    "fig, ax = plt.subplots()\n",
    "plt.xlim([-.5, 10])\n",
    "plt.ylim([-.5, 10])\n",
    "plt.grid()\n",
    "plt.tight_layout()\n",
    "\n",
    "fig.canvas.draw()\n",
    "\n",
    "p1_w = np.vstack([1, 2, 0.5])\n",
    "Qp1_w = np.ùëëùëñùëéùëî([0.08,0.6,0.02])\n",
    "\n",
    "z1_p_r = np.vstack([4., .7])\n",
    "W1 = np.diag([0.25, 0.04])\n",
    "\n",
    "z1_w, Qz1 = to_world_frame(p1_w, Qp1_w, z1_p_r, W1)\n",
    "\n",
    "DrawRobot(fig, ax, p1_w, label='R1', color='red')  \n",
    "ax.plot(z1_w[0, 0], z1_w[1, 0], 'o', label='Z1', color='green')\n",
    "PlotEllipse(fig, ax, z1_w, Qz1, color='green')\n",
    "\n",
    "plt.legend()\n",
    "print('---- Exercise 4.1.2 ----\\n'+\n",
    "      'Wz1_w = \\n{}\\n'.format(Qz1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expected output:\n",
    "\n",
    "```\n",
    "---- Exercise 4.1.2 ----\n",
    "Wz1_w = \n",
    "[[ 0.94677477 -0.23978943]\n",
    " [-0.23978943  0.94322523]]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Another robot `R2` is at pose $p_2 \\sim ([6m., 4m., 2.1rad.]^T, \\Sigma_2)$ with $\\Sigma_2 = diag([0.20,0.09,\n",
    " 0.03])$. Plot `p2` and its ellipse (covariance) in green ($sigma=1$). Compute the relative\n",
    " pose `p12` between `R1` and `R2`. For that, take a look at the file ‚ÄúClarifying the\n",
    " relative pose between to poses‚Äù and implement the two possible ways to obtain\n",
    " such pose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_composition1(p1_w, Qp1_w, p2_w, Qp2_w):\n",
    "    # TODO: Implement function\n",
    "    raise NotImplementedError\n",
    "    \n",
    "    return p12_w, Qp12_w\n",
    "\n",
    "def inverse_composition2(p1_w, Qp1_w, p2_w, Qp2_w):\n",
    "    # TODO: Implement function\n",
    "    raise NotImplementedError\n",
    "    \n",
    "    return p12_w, Qp12_w\n",
    "\n",
    "\n",
    "p1_w = np.vstack([1., 2., 0.5])\n",
    "Qp1_w = np.diag([0.08, 0.6, 0.02])\n",
    "p2_w = np.vstack([6., 4., 2.1])\n",
    "Qp2_w = np.diag([0.20, 0.09, 0.03])\n",
    "\n",
    "p12_w, Qp12_w = inverse_composition1(p1_w, Qp1_w, p2_w, Qp2_w)\n",
    "print( '----\\tExercise 4.1.3 with method 1\\t----\\n'+\n",
    "        'p12_w = {}\\'\\n'.format(p12_w.flatten())+\n",
    "        'Qp12_w = \\n{}\\n'.format(Qp12_w))\n",
    "\n",
    "\n",
    "p12_w, Qp12_w = inverse_composition2(p1_w, Qp1_w, p2_w, Qp2_w)\n",
    "print( '----\\tExercise 4.1.3 with method 2\\t----\\n'+\n",
    "        'p12_w = {}\\'\\n'.format(p12_w.flatten())+\n",
    "        'Qp12_w = \\n{}\\n'.format(Qp12_w))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expected results:\n",
    " ```\n",
    " p12_w = [ 5.34676389 -0.64196257  1.6       ]'\n",
    " \n",
    " Qp12_w = \n",
    " [[0.38248035 0.24115    0.01283925]\n",
    " [0.24115    1.16751965 0.10693528]\n",
    " [0.01283925 0.10693528 0.05      ]]\n",
    " ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. According to the information that we have about the position of the landmark m in\n",
    " the world coordinates (provided by R1), compute the *predicted observation*\n",
    " distribution of $z_{2p} =[r, \\alpha] \\sim N(z_{2p}, W_{2p})$ by a range-bearing sensor from `R2`.\n",
    " Hint: We need to compute the covariance of the predicted observation in Polar\n",
    " coordinates $(W_{2p})$. For that, use the following Jacobian:\n",
    " \n",
    " $$\n",
    "     \\frac{\\partial{p}}{\\partial{c}} = \n",
    "     \\begin{bmatrix}\n",
    "         \\cos{(\\alpha+\\theta)}  & \\sin{(\\alpha+\\theta)} \\\\\n",
    "         \\sin{(\\alpha+\\theta)} / r  & \\cos{(\\alpha+\\theta)} / r\n",
    "     \\end{bmatrix}\n",
    " $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predicted_obs_from_pov(p1_w, z1_w, Qz1_w):\n",
    "    \"\"\" Method to translate a pose+covariance in the world frame to an observation.\n",
    "    \n",
    "        This method only translated the landmark to the pov of the robot.\n",
    "        It does not simulate a new observation.\n",
    "        \n",
    "        Args:\n",
    "            p1_w: Pose of the robot which acts as pov\n",
    "            z1_w: Landmark observed in cartesian coordinates(world frame)\n",
    "            Qz1_w: Covariance associated to the landmark.\n",
    "        Returns:\n",
    "            z2_pr: Expected observation of z1 from pov of p1_w\n",
    "            W2_p: Covariance associated to z2_pr\n",
    "    \"\"\"\n",
    "\n",
    "    # TODO: Implement function\n",
    "    raise NotImplementedError\n",
    "    \n",
    "    return z2_pr, W2_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p2_w = np.vstack([6., 4., 2.1])\n",
    "\n",
    "z2_pr, W2_p = predicted_obs_from_pov(p2_w, z1_w, Qz1)\n",
    "print( '---- Exercise 4.1.4 ----\\n'+\n",
    "    'z2p_r = {}\\'\\n'.format(z2_pr.flatten())+\n",
    "    'W2_p = \\n{}\\n'.format(W2_p)    \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expected output:\n",
    "```\n",
    "---- Exercise 4.1.4 ----\n",
    "z2p_r = [3.94880545 0.58862004]'\n",
    "W2_p = \n",
    "[[ 1.13481128 -0.03710981]\n",
    " [-0.03710981  0.04843106]]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Assume now that a measurement $z_2 = [4 m., 0.3 rad.]^T$ of the landmark is taken\n",
    " from R2 with a sensor having the same precision as that of R1 ($W_{2p}= W_{1p}$)\n",
    " a-b-What is the pdf of the observed landmark according to this observation?\n",
    " Plot the corresponding ellipse (in green, sigma=1).\n",
    " Two different pdf‚Äôs are now associated to the same landmark.\n",
    "    1. Is that a contradiction?\n",
    "    2. Can you work out a solution that combines these two ‚Äúpieces of\n",
    "     information‚Äù? Plot it (in red).\n",
    "     \n",
    "<figure style=\"text-align:center\">\n",
    "  <img src=\"images/fig4-1-2.png\" width=\"400\" alt=\"\">\n",
    "  <figcaption>Fig. 2: Results from the last exercise </figcaption>\n",
    "</figure>    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_pdfs(p1_w, Qp1_w, p2_w, Qp2_w):\n",
    "    # TODO: Implement function\n",
    "    raise NotImplementedError\n",
    "    \n",
    "# MATPLOTLIB\n",
    "fig, ax = plt.subplots()\n",
    "plt.xlim([-.5, 10])\n",
    "plt.ylim([-.5, 10])\n",
    "plt.grid()\n",
    "plt.tight_layout()\n",
    "\n",
    "fig.canvas.draw()\n",
    "\n",
    "z2_p_r = np.vstack([4., .3])\n",
    "Wz2_p_r = np.diag([0.25, 0.04])\n",
    "\n",
    "z1_w, Qz1 = to_world_frame(p1_w, Qp1_w, z1_p_r, W1)\n",
    "z2_w, Qz2 = to_world_frame(p2_w, Qp2_w, z2_p_r, W1)\n",
    "\n",
    "DrawRobot(fig, ax, p1_w, label='R1', color='blue')\n",
    "PlotEllipse(fig, ax, p1_w, Qp1_w, color='blue')\n",
    "\n",
    "DrawRobot(fig, ax, p2_w, label='R2', color='green')\n",
    "PlotEllipse(fig, ax, p2_w, Qp2_w, color='green')\n",
    "   \n",
    "ax.plot(z1_w[0, 0], z1_w[1, 0], 'o', label='Z1', color='blue')\n",
    "PlotEllipse(fig, ax, z1_w, Qz1, color='blue')\n",
    "          \n",
    "ax.plot(z2_w[0, 0], z2_w[1, 0], 'o', label='Z2', color='green')\n",
    "PlotEllipse(fig, ax, z2_w, Qz2, color='green')\n",
    "\n",
    "z_w, Wz_w = combine_pdfs(z1_w, Qz1, z2_w, Qz2)\n",
    "ax.plot(z_w[0, 0], Wz_w[1, 0], 'o', label='Z3', color='red')\n",
    "PlotEllipse(fig, ax, z_w, Wz_w, color='red')\n",
    "          \n",
    "plt.legend()\n",
    "\n",
    "# Print results\n",
    "print( '----\\tExercise 4.1.5\\t----\\n'+\n",
    "    'z2_w = {}\\'\\n'.format(z2_w.flatten())+\n",
    "    'Qz2 = \\n{}\\n'.format(Qz2)\n",
    "    )\n",
    "\n",
    "# Print results\n",
    "print( '----\\tExercise 4.1.5 parte 2\\t----\\n'+\n",
    "    'z_w = {}\\'\\n'.format(z_w.flatten())+\n",
    "    'Wz_w = \\n{}\\n'.format(Wz_w)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expected ouputs:\n",
    "\n",
    "### Sensor measurement from R2\n",
    "\n",
    "```\n",
    "z2_w = [3.05042514 6.70185272]'\n",
    "Qz2 = \n",
    "[[0.84693794 0.4333316 ]\n",
    " [0.4333316  0.81306206]]\n",
    "```\n",
    "\n",
    "### Combined information\n",
    "```\n",
    "---- Exercise 4.1.5 parte 2 ----\n",
    "z_w = [2.58757252 6.15534036]'\n",
    "Wz_w = \n",
    "[[0.37966125 0.07773125]\n",
    " [0.07773125 0.36999739]]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
