{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Robot sensing\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In order to carry out tasks like localization or navigation, a mobile robot has to perceive its workspace. A variety of sensors can be used for that, as well as a number of probabilitic models for managing their behaviour."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:green\">OPTIONAL</span>\n",
    "\n",
    "<span style=\"color:green\">As commented, a number of sensors can be mounted on a mobile robot. In the robotic sensing lecture we discused some of the most popular ones. As an optional exercise, you can look for interesting information about any of them (or any one not listed below) and further describe it here to complete your knowledge.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Sensors for autonomous robots\n",
    "\n",
    "### 4.1.1 Classification\n",
    "### 4.1.2 Beacons\n",
    "#### GPS\n",
    "### 4.1.3 Range sensors\n",
    "#### Sonar\n",
    "#### Infrared\n",
    "#### Laser scanner\n",
    "### 4.1.4 Cameras\n",
    "### 4.1.5 RGB-D cameras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:green\">***END OF OPTIONAL PART***</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Probabilistic sensor models\n",
    "\n",
    "Typically, the sensors used onboard the robot do not deliver the exact truth of the quantities they are measuring, but a perturbed version. To model this behaviour, sensors' measurements are modelled by the probability distribution $p(z|v)$, where z models the measurmenet and v is the ground truth."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.1 Landmark-based models\n",
    "\n",
    "When the map consist of a collection of landmarks $m={m_i}, i=1,\\dots,N$, then the sensors used to provide observations of those landmarks measure:\n",
    "\n",
    "- **Distance/range** (*e.g.* radio, GPS, etc.): $z_i = d_i = h_i(x,m)+w_i$\n",
    "- **Bearing** (*e.g.* camera): $z_i = \\theta_i = h_i(x,m)+w_i$\n",
    "- **Distance/range and bearing** (*e.g.* stereo, features in a scan, etc.) $z_i = [d_i,\\theta_i]^T = h_i(x,m)+w_i$ *(in this case, $h_i(x,m)$ and $w_i$ are 2D vectors)*\n",
    "\n",
    "These types of maps and sensor measurements pose a new problem: **data association**, that is, with which landmark $m_i$ correspond the observation $z_i$ to: $h_i(x,m)=h(x,m_i)$. This problem is usually addressed by applying Chi-squared tests, although for the shake of simplicity in this book we will consider it as solved. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Playing with landmarks and robot poses\n",
    "\n",
    "In the remaining of this section we will familiarise ourselves with the process of observing landmarks from robots located at certain poses, as well as the transformations needed to make use of these observations, that is, to express those observations into the world frame and backwards.\n",
    "\n",
    "Some relevant concepts:\n",
    "\n",
    "- **World frame**: $x, y$ coordinates from a selected point of reference $(0, 0)$. We use to keep track of the robots pose, and within the map.\n",
    "- **Observation**: Information from the real world provided by a sensor, from the point of view (*pov*) of a certain robot.\n",
    "- **Range-bearing sensor**: Sensor model being used in this lesson. They detect how far is an object $(d)$ and its orientation relative to the robot's $(\\theta)$.\n",
    "\n",
    "The main tools for that are:\n",
    "\n",
    "- the composition of two poses.\n",
    "- the composition of a pose and a landmark.\n",
    "- the propagation of uncertainty through the Jacobians of these compositions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib notebook\n",
    "%matplotlib inline\n",
    "\n",
    "# IMPORTS\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "from utils.PlotEllipse import PlotEllipse\n",
    "from utils.DrawRobot import DrawRobot\n",
    "from utils.tcomp import tcomp\n",
    "from utils.tinv import tinv, jac_tinv1 as jac_tinv\n",
    "from utils.Jacobians import J1, J2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will address several problems of incremental complexity. The following figures will help you to follow the exercise. Concretely:\n",
    "\n",
    "1. We start with a robot ($R1$) placed at a perflectly known pose $p_1$ in the world frame (no uncertainty at this point), which observes a landmark with a range-bearing (polar) sensor affected by an error characterized with the covarince $W_{1p}$, providing a measurement $z_{1p}$ (In ipolar coordinates). **Our goal is to express the landmark position in the world frame**.\n",
    "2. In the second point, the robot pose is not perfectly known, but it follows a random variable (RV) so $p_1 \\sim N(\\overline{p}_1, \\Sigma_{p_1}).$. Again, **we have to express the landmark position in the world frame** and analyze what changes.\n",
    "3. Then, a second robot comes to play, and **we are asked to retrieve the relative pose $p_{12}$ between both robots**.\n",
    "4. At this point **we predict and obsevation from $R2$ to the landmark**. That is, using the range-bearing observation model and the information of the landmark position and uncertainty as provided by $R1$, we retrieve $z_{2p}$ expressed in polar coordiantes, as well as its associated uncertainty. \n",
    "5. Finally, $R2$ takes an observation of the landmark with its own sensor, so now we have two observations of the same landmark, one by $R1$ and another one by $R2$. **How could we combine these pieces of information?**\n",
    "\n",
    "\n",
    "\n",
    "<center>\n",
    "<img src=\"images/fig4-1-1.png\" width=\"800\">\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Express the observed landmark in coordinates of the world frame.** Let’s consider a robot R1 at a perfectly known pose $p_1 = [1, 2, 0.5]^T$ which observes\n",
    " a landmark $m$ with a range-bearing (polar) sensor affected by a zero-mean\n",
    " Gaussian error with covariance $W_{1p} = diag\\left([0.25, 0.04]\\right)$. The sensor provides the\n",
    " measurement $z_{1p} = [4m., 0.7rad.]^T$. \n",
    " \n",
    " Compute the Gaussian probability distribution  (mean and covariance) of the landmark observation in the world frame (the same as the robot)  and plot its corresponding ellipse (in magenta, $\\sigma=1$). Concretely, you have to complete the ``to_world_frame()`` function, and modify the demo code to show the ellipse representing the uncertainty. \n",
    " \n",
    " Consider the following:\n",
    " \n",
    " - You can express a sensor measurement in polar coordinates ($z_p=[r,\\alpha]^T$) as cartesian coordinates ($z_c=[z_x,z_y]^T)$ by:\n",
    " \n",
    " $$\n",
    "     z_c = \\begin{bmatrix} z_x \\\\ z_y \\end{bmatrix} \n",
    "         = \\begin{bmatrix} r \\ cos\\alpha \\\\ r \\ sin\\alpha \\end{bmatrix} \n",
    "         = f(r,\\alpha)\n",
    " $$\n",
    " \n",
    " - While computing the covariance of the landmark observation, you have to start by computing the covariance of the observation in the Cartesian robot $R1$ frame. That is:\n",
    " \n",
    " $$  \n",
    " W_{c} = \\frac{\\partial f(z_x,z_y)}{\\partial \\{r,\\alpha\\}} \\ W_{p} \\ \\frac{\\partial f(z_x,z_y)}{\\partial \\{r,\\alpha\\}}^T\n",
    " $$\n",
    "   \n",
    "   Then you can get the convariance in the world frame as:\n",
    "   \n",
    "   $$ W_{z\\_w} = \\frac{\\partial f(p,z_c)}{\\partial p} \\ Q_{p1\\_w} \\ \\left( \\frac{\\partial f(p,z_c)}{\\partial p} \\right)^T +\n",
    "        \\frac{\\partial f(p,z_c)}{\\partial z_c} \\ W_{c} \\ \\left( \\frac{\\partial f(p,z_c)}{\\partial z_c} \\right)^T\n",
    "   $$\n",
    "   \n",
    "   where $f(p,z_c) = p \\oplus z_c$, that is, the composition of the pose and the landmark.\n",
    "   \n",
    "   - Note that $\\frac{\\partial f(p,z_c)}{\\partial p}$ and $\\frac{\\partial f(p,z_c)}{\\partial z_c}$ are the same Jacobians as previously used to compose two poses in *robot motion*, but with a reduced size since **while working with landmarks the orientation is meaningless, only the position matters**. The functions ``J1()`` and ``J2()`` implement these jacobians for you.\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_world_frame(p1_w, Qp1_w, z1_p_r, W1):\n",
    "    \"\"\" Covert the observation z1_p_r to the world frame\n",
    "    \n",
    "        Args:\n",
    "            p1_w: Pose of the robot(in world frame)\n",
    "            Qp1_w: Covariance of the robot\n",
    "            z1_p_r: Observation to a landmark (polar coordinates) from robots perspective\n",
    "            W1: Covariance of the sensor in polar coordinates\n",
    "    \n",
    "        Returns:\n",
    "            z1_w: Pose of landmark in the world frame\n",
    "            Wz1: Covariance associated to z1_w\n",
    "    \"\"\"\n",
    "    \n",
    "    # Definition of useful variables\n",
    "    r, a = z1_p_r[0,0], z1_p_r[1,0]\n",
    "    s, c = np.sin(a), np.cos(a)\n",
    "\n",
    "    # Jacobian to convert the measurement uncertainty from polar to cartesian coordinates\n",
    "    Jac_pol_car = np.array([\n",
    "        [c, -r*s],\n",
    "        [s, r*c]\n",
    "    ])\n",
    "\n",
    "    # Built a tuple with:\n",
    "    # z1_car_rel[0]: coordinates of the sensor measurement in cartesian coordinates relative to robot position\n",
    "    # z1_car_rel[1]: its associated uncertainty expressed in cartesian coordinates\n",
    "    z1_car_rel = (\n",
    "            np.vstack([r*c,r*s]), # position\n",
    "            Jac_pol_car@W1@np.transpose(Jac_pol_car) # uncertainty\n",
    "            )\n",
    "    \n",
    "    z1_ext = np.vstack([z1_car_rel[0], 0]) # Extends z1 for its usage in the Jacobian functions J1 and J2\n",
    "\n",
    "    # Build the jacobians \n",
    "    Jac_ap = J1(p1_w ,z1_ext)[0:2,:] # Jacobian for expressing the uncertainty in the robot pose in a global frame\n",
    "    Jac_aa = J2(p1_w ,z1_ext)[0:2,0:2] # This one expresses the uncertainty in the measurment in a global frame\n",
    "    \n",
    "    z1_w = tcomp(p1_w ,z1_ext)[0:2,[0]] # Compute coordinates of the landmark in the world\n",
    "    Wz1 = (Jac_ap @ Qp1_w @ np.transpose(Jac_ap)\n",
    "          + Jac_aa @ z1_car_rel[1] @ np.transpose(Jac_aa)) # Finally, propagate the covariance!\n",
    "    \n",
    "    return z1_w, Wz1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----\tExercise 4.1.1\t----\n",
      "z1_w = [2.44943102 5.72815634]'\n",
      "Wz1_w = \n",
      "[[ 0.58879177 -0.13171532]\n",
      " [-0.13171532  0.30120823]]\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Robot\n",
    "p1_w = np.vstack([1, 2, 0.5]) # Robot R1 pose\n",
    "Qp1_w = np.zeros((3, 3)) # Robot pose convariance matrix (uncertainty)\n",
    "\n",
    "# Landmark observation\n",
    "z1_p_r = np.vstack([4., .7]) # Measurement/Observation\n",
    "W1 = np.diag([0.25, 0.04]) # Sensor noise covariance\n",
    "\n",
    "# Express the landmark observation in the world frame (mean and covariance)\n",
    "z1_w, Wz1 = to_world_frame(p1_w, Qp1_w, z1_p_r, W1)\n",
    "\n",
    "# Visualize the results\n",
    "fig, ax = plt.subplots()\n",
    "plt.xlim([-.5, 10])\n",
    "plt.ylim([-.5, 10])\n",
    "plt.grid()\n",
    "plt.tight_layout()\n",
    "\n",
    "DrawRobot(fig, ax, p1_w, label='R1', color='blue')\n",
    "    \n",
    "ax.plot(z1_w[0, 0], z1_w[1, 0], 'o', label='Z1', color='green')\n",
    "PlotEllipse(fig, ax, z1_w, Wz1, color='green')\n",
    "\n",
    "plt.legend()\n",
    "print('----\\tExercise 4.1.1\\t----\\n'+\n",
    "      'z1_w = {}\\'\\n'.format(z1_w.flatten())\n",
    "      + 'Wz1_w = \\n{}\\n'.format(Wz1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">Expected results for demo:</span>\n",
    "\n",
    "\n",
    "```\n",
    "---- Exercise 4.1.1 ----\n",
    "z1_w = [2.44943102 5.72815634]'\n",
    "Wz1_w = \n",
    "[[ 0.58879177 -0.13171532]\n",
    " [-0.13171532  0.30120823]]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **Adding uncertainty to the robot posiion.** Now, let’s assume that the robot pose is not known, but it is a RV that follows a\n",
    "Gaussian probability distribution: $p_1 \\sim N([1, 2, 0.5]^T, \\Sigma_1)$ with $\\Sigma_1 = diag([0.08,0.6,\n",
    "0.02 ])$.\n",
    "\n",
    "    1. Compute the covariance matrix $\\Sigma_{m1}$ of the landmark in the world frame and\n",
    "     plot it as an ellipse centered at the mean $m_1$ (in blue, $sigma= 1$). Plot also\n",
    "     the covariance of the robot pose (in blue, $sigma= 1$).\n",
    "     \n",
    "    2. Compare the covariance with that obtained in the previous case. Is it\n",
    "     bigger? Is it bigger than that of the robot? Why?  **<span style=\"color:orangered\">Comment this in the Student discussion</span>**\n",
    "     \n",
    "     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Exercise 4.1.2 ----\n",
      "Wz1_w = \n",
      "[[ 0.94677477 -0.23978943]\n",
      " [-0.23978943  0.94322523]]\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Robot\n",
    "p1_w = np.vstack([1, 2, 0.5]) # Robot R1 pose\n",
    "Qp1_w = np.diag([0.08,0.6,0.02])  # Robot pose convariance matrix (uncertainty)\n",
    "\n",
    "# Landmark observation\n",
    "z1_p_r = np.vstack([4., .7]) # Measurement/Observation\n",
    "W1 = np.diag([0.25, 0.04]) # Sensor noise covariance\n",
    "\n",
    "# Express the landmark observation in the world frame (mean and covariance)\n",
    "z1_w, Wz1 = to_world_frame(p1_w, Qp1_w, z1_p_r, W1)\n",
    "\n",
    "# MATPLOTLIB\n",
    "fig, ax = plt.subplots()\n",
    "plt.xlim([-.5, 10])\n",
    "plt.ylim([-.5, 10])\n",
    "plt.grid()\n",
    "plt.tight_layout()\n",
    "\n",
    "fig.canvas.draw()\n",
    "\n",
    "DrawRobot(fig, ax, p1_w, label='R1', color='red')  \n",
    "PlotEllipse(fig, ax, p1_w, Qp1_w , color='blue')\n",
    "\n",
    "ax.plot(z1_w[0, 0], z1_w[1, 0], 'o', label='Z1', color='green')\n",
    "PlotEllipse(fig, ax, z1_w, Wz1, color='green')\n",
    "\n",
    "plt.legend()\n",
    "print('---- Exercise 4.1.2 ----\\n'+\n",
    "      'Wz1_w = \\n{}\\n'.format(Wz1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">Expected results for demo:</span>\n",
    "\n",
    "```\n",
    "---- Exercise 4.1.2 ----\n",
    "Wz1_w = \n",
    "[[ 0.94677477 -0.23978943]\n",
    " [-0.23978943  0.94322523]]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. **Getting the relative pose between two robots**. Another robot `R2` is at pose $p_2 \\sim ([6m., 4m., 2.1rad.]^T, \\Sigma_2)$ with $\\Sigma_2 = diag([0.20,0.09,\n",
    " 0.03])$. Plot `p2` and its ellipse (covariance) in green ($sigma=1$). Compute the relative\n",
    " pose `p12` between `R1` and `R2`. \n",
    " \n",
    " This relative pose can be obtained in two different ways:\n",
    " - Through the composition of poses, but using $\\ominus p1$ instead of $p1$. Implement it in ``inverse_composition1()``.\n",
    " \n",
    " Mean: \n",
    " \n",
    " $$\n",
    " p12 = \\ominus p1 \\oplus p2 = f(\\ominus p1, p2) = \n",
    " \\begin{bmatrix} \n",
    "  x_{\\ominus p1} + x_{p2} cos \\theta_{\\ominus p1} - y_{p2} sin \\theta_{\\ominus p1} \\\\\n",
    "  y_{\\ominus p1} + x_{p2} sin \\theta_{\\ominus p1} + y_{p2} cos \\theta_{\\ominus p1} \\\\\n",
    "  \\theta_{\\ominus p1} + \\theta_{p2}\n",
    " \\end{bmatrix}\n",
    " $$\n",
    " \n",
    " Covariance:\n",
    " \n",
    " $$\n",
    " \\Sigma_{p12} = \\frac{\\partial p12}{\\partial \\ominus p1} \\frac{\\ominus p1}{\\partial p1} \\Sigma_{p1} \\frac{\\ominus p1}{\\partial p1}^T \\frac{\\partial p12}{\\partial \\ominus p1}^T \n",
    " +\n",
    " \\frac{\\partial p12}{\\partial p2} \\Sigma_{p2}  \\frac{\\partial p12}{\\partial p2}^T\n",
    " \\\\\n",
    " \\text{Applying the Chain rule} \\rightarrow \\Sigma_{p12} = \\frac{\\partial p12}{\\partial \\ominus p1} \\Sigma_{\\ominus p1} \\frac{\\partial p12}{\\partial \\ominus p1}^T\n",
    " +\n",
    " \\frac{\\partial p12}{\\partial p2} \\Sigma_{p2}  \\frac{\\partial p12}{\\partial p2}^T\n",
    " $$\n",
    " \n",
    " Being:\n",
    " \n",
    " $$\n",
    " \\frac{\\partial p12}{\\partial \\ominus p1} = \n",
    " \\begin{bmatrix}\n",
    " 1 & 0 & -x_{p2} sin \\theta_{\\ominus p1} - y_{p2} cos \\theta_{\\ominus p1} \\\\\n",
    " 0 & 1 & x_{p2} cos \\theta_{\\ominus p1} - y_{p2} sin \\theta_{\\ominus p1} \\\\\n",
    " 0 & 0 & 1\n",
    " \\end{bmatrix}  \n",
    " \\; \\; \\; \\; \\; \\frac{\\partial p12}{\\partial p2} = \n",
    " \\begin{bmatrix}\n",
    "cos \\theta_{\\ominus p1} & -sin \\theta_{\\ominus p1} & 0\\\\\n",
    "sin \\theta_{\\ominus p1} & cos \\theta_{\\ominus p1} & 0\\\\\n",
    " 0 & 0 & 1\n",
    " \\end{bmatrix}\n",
    " \\\\\n",
    " \\frac{\\partial \\ominus p1}{\\partial p1} = \n",
    " \\begin{bmatrix}\n",
    " -cos \\theta_{p1} & -sin \\theta_{p1} & x_{p1} sin \\theta_{p1} - y_{p1} cos \\theta_{p1} \\\\\n",
    " sin \\theta_{p1} & -cos \\theta_{p1} & x_{p1} cos \\theta_{p1} + y_{p1} sin \\theta_{p1}\\\\\n",
    " 0 & 0 & -1 \\\\\n",
    " \\end{bmatrix}\n",
    " \\; \\; \\; \\; \\; \\Sigma_{\\ominus p1} = \\frac{\\partial \\ominus p1}{\\partial p1} \\Sigma_{p1} \\frac{\\partial \\ominus p1}{\\partial p1}^T\n",
    " $$ \n",
    " \n",
    " - Using the inverse composition of poses. This one is given for you in ``inverse_composition2()``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_composition1(p1_w, Qp1_w, p2_w, Qp2_w):\n",
    "    jac_inv_p = jac_tinv(p1_w)\n",
    "\n",
    "    inv_r1 = (\n",
    "        tinv(p1_w),\n",
    "        jac_inv_p @ Qp1_w @ jac_inv_p.T\n",
    "    )\n",
    "    \n",
    "    jac_p12_inv = J1(inv_r1[0], p2_w)\n",
    "    jac_p12_p2 = J2(inv_r1[0], p2_w)\n",
    "    \n",
    "    p12_w = tcomp(inv_r1[0], p2_w)\n",
    "    \n",
    "    Qp12_w = (\n",
    "            jac_p12_inv@inv_r1[1]@jac_p12_inv.T\n",
    "            + jac_p12_p2@Qp2_w@jac_p12_p2.T\n",
    "        )\n",
    "    \n",
    "    return p12_w, Qp12_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_composition2(p1_w, Qp1_w, p2_w, Qp2_w):\n",
    "    dx, dy = p2_w[0, 0]-p1_w[0, 0], p2_w[1, 0]-p1_w[1, 0]\n",
    "    a = p2_w[2, 0] - p1_w[2, 0]\n",
    "    c, s = np.cos(p1_w[2, 0]), np.sin(p1_w[2, 0])\n",
    "\n",
    "    p12_w = np.array([\n",
    "        [dx*c + dy*s],\n",
    "        [-dx*s + dy*c],\n",
    "        [a]])\n",
    "    \n",
    "    jac_p12_r1 = np.array([\n",
    "        [-c, -s, -dx*s + dy*c],\n",
    "        [s, -c, -dx*c - dy*s],\n",
    "        [0, 0, -1]\n",
    "    ])\n",
    "\n",
    "    jac_p12_r2 = np.array([\n",
    "        [c, s, 0],\n",
    "        [-s, c, 0],\n",
    "        [0, 0, -1]\n",
    "    ])\n",
    "\n",
    "    #jac_p1_pinv = np.linalg.inv(jac_tinv(r1[0]))\n",
    "\n",
    "    Qp12_w = jac_p12_r1@Qp1_w@jac_p12_r1.T + jac_p12_r2@Qp2_w@jac_p12_r2.T\n",
    "\n",
    "    return p12_w, Qp12_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----\tExercise 4.1.3 with method 1\t----\n",
      "p12_w = [ 5.34676389 -0.64196257  1.6       ]'\n",
      "Qp12_w = \n",
      "[[0.38248035 0.24115    0.01283925]\n",
      " [0.24115    1.16751965 0.10693528]\n",
      " [0.01283925 0.10693528 0.05      ]]\n",
      "\n",
      "----\tExercise 4.1.3 with method 2\t----\n",
      "p12_w = [ 5.34676389 -0.64196257  1.6       ]'\n",
      "Qp12_w = \n",
      "[[0.38248035 0.24115    0.01283925]\n",
      " [0.24115    1.16751965 0.10693528]\n",
      " [0.01283925 0.10693528 0.05      ]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Robot R1\n",
    "p1_w = np.vstack([1., 2., 0.5])\n",
    "Qp1_w = np.diag([0.08, 0.6, 0.02])\n",
    "\n",
    "# Robot R2\n",
    "p2_w = np.vstack([6., 4., 2.1])\n",
    "Qp2_w = np.diag([0.20, 0.09, 0.03])\n",
    "\n",
    "# Obtain the relative pose p12 between both robots through the composition of poses\n",
    "p12_w, Qp12_w = inverse_composition1(p1_w, Qp1_w, p2_w, Qp2_w)\n",
    "print( '----\\tExercise 4.1.3 with method 1\\t----\\n'+\n",
    "        'p12_w = {}\\'\\n'.format(p12_w.flatten())+\n",
    "        'Qp12_w = \\n{}\\n'.format(Qp12_w))\n",
    "\n",
    "# Obtain the relative pose p12 between both robots through the inverse composition of poses\n",
    "p12_w, Qp12_w = inverse_composition2(p1_w, Qp1_w, p2_w, Qp2_w)\n",
    "print( '----\\tExercise 4.1.3 with method 2\\t----\\n'+\n",
    "        'p12_w = {}\\'\\n'.format(p12_w.flatten())+\n",
    "        'Qp12_w = \\n{}\\n'.format(Qp12_w))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">Expected results:</span>\n",
    " ```\n",
    " p12_w = [ 5.34676389 -0.64196257  1.6       ]'\n",
    " \n",
    " Qp12_w = \n",
    " [[0.38248035 0.24115    0.01283925]\n",
    " [0.24115    1.16751965 0.10693528]\n",
    " [0.01283925 0.10693528 0.05      ]]\n",
    " ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. **Predicting an observation from the second robot.** According to the information, provided by R1, that we have about the position of the landmark m in\n",
    " the world coordinates (its location $z_{1\\_w}$ and its associated uncertainty $W_{z_1\\_w}$), compute the *predicted observation*\n",
    " distribution of $z_{2p} =[r, \\alpha] \\sim N(z_{2p}, W_{2p})$ as taken by a range-bearing sensor mounted on `R2`.\n",
    " Consider the following:\n",
    " \n",
    " - The range-bearing model for taking measurements is *(Notes: use ``np.arctan2()`` for computing the angle. At this point, ignore the noise $w_i$)*:\n",
    " \n",
    " $$\n",
    " z_i = \\begin{bmatrix} r_i \\\\ \\alpha_i \\end{bmatrix} = h(x,m_i) + w_i = \n",
    " \\begin{bmatrix} \\sqrt((x_i-x)^2+(y_i-y)^2) \\\\ atan(\\frac{y_i-y}{x_i-x}) - \\theta \\end{bmatrix} \n",
    " + w_i\n",
    " $$\n",
    " \n",
    " - We need to compute the covariance of the predicted observation in Polar  coordinates $(W_{2p})$. For that, use the following Jacobian: \n",
    " $$\n",
    "     \\frac{\\partial{p}}{\\partial{c}} = \n",
    "     \\begin{bmatrix}\n",
    "         \\cos{(\\alpha+\\theta)}  & \\sin{(\\alpha+\\theta)} \\\\\n",
    "         -\\sin{(\\alpha+\\theta)} / r  & \\cos{(\\alpha+\\theta)} / r\n",
    "     \\end{bmatrix}\n",
    " $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predicted_obs_from_pov(p1_w, z1_w, Wz1_w):\n",
    "    \"\"\" Method to translate a pose+covariance in the world frame to an observation.\n",
    "    \n",
    "        This method only translated the landmark to the pov of the robot.\n",
    "        It does not simulate a new observation.\n",
    "        \n",
    "        Args:\n",
    "            p1_w: Pose of the robot which acts as pov\n",
    "            z1_w: Landmark observed in cartesian coordinates(world frame)\n",
    "            Wz1_w: Covariance associated to the landmark.\n",
    "        Returns:\n",
    "            z2_pr: Expected observation of z1 from pov of p1_w\n",
    "            W2_p: Covariance associated to z2_pr\n",
    "    \"\"\"\n",
    "\n",
    "    # Take a measurement using the range-bearing model\n",
    "    z2_pr = np.vstack([\n",
    "            np.sqrt(np.square(z1_w[0,0]-p1_w[0,0])+np.square(z1_w[1,0]-p1_w[1,0])), # distance\n",
    "            np.arctan2(z1_w[1,0]-p1_w[1,0],z1_w[0,0]-p1_w[0,0])-p1_w[2,0] # angle\n",
    "        ])\n",
    "      \n",
    "    # Jacobian from cartesian to polar at z2p_r when the covariance is in\n",
    "    # global coordianes\n",
    "    theta = z2_pr[1, 0] + p1_w[2, 0] \n",
    "    s, c = np.sin(theta), np.cos(theta)\n",
    "    r = z2_pr[0, 0]\n",
    "\n",
    "    Jac_car_pol = np.array([\n",
    "        [c, s],\n",
    "        [-s/r, c/r]\n",
    "    ])\n",
    "\n",
    "    # Finally, propagate the uncertainty to polar coordinates in the\n",
    "    # robot frame\n",
    "    W2_p = Jac_car_pol@Wz1_w@Jac_car_pol.T\n",
    "    \n",
    "    return z2_pr, W2_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Exercise 4.1.4 ----\n",
      "z2p_r = [3.94880545 0.58862004]'\n",
      "W2_p = \n",
      "[[ 1.13481128 -0.03710981]\n",
      " [-0.03710981  0.04843106]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "p2_w = np.vstack([6., 4., 2.1])\n",
    "\n",
    "z2_pr, W2_p = predicted_obs_from_pov(p2_w, z1_w, Wz1)\n",
    "print( '---- Exercise 4.1.4 ----\\n'+\n",
    "    'z2p_r = {}\\'\\n'.format(z2_pr.flatten())+\n",
    "    'W2_p = \\n{}\\n'.format(W2_p)    \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">Expected output:</span>\n",
    "```\n",
    "---- Exercise 4.1.4 ----\n",
    "z2p_r = [3.94880545 0.58862004]'\n",
    "W2_p = \n",
    "[[ 1.13481128 -0.03710981]\n",
    " [-0.03710981  0.04843106]]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. **Combining observations of the same landmark.** Assume now that a measurement $z_2 = [4 m., 0.3 rad.]^T$ of the landmark is taken\n",
    " from R2 with a sensor having the same precision as that of R1 ($W_{2p}= W_{1p}$)\n",
    " \n",
    " 1. What is the pdf of the observed landmark according to this observation? Plot the corresponding ellipse (in green, sigma=1).\n",
    " 2. Two different pdf’s are now associated to the same landmark.\n",
    "    1. Is that a contradiction?\n",
    "    2. Can you work out a solution that combines these two “pieces of\n",
    "     information”? Plot it in red. **<span style=\"color:orangered\">Comment this in the Student discussion</span>**\n",
    "     \n",
    "    \n",
    "<figure style=\"text-align:center\">\n",
    "  <img src=\"images/fig4-1-2.png\" width=\"400\" alt=\"\">\n",
    "  <figcaption>Fig. 2: Results from the last exercise </figcaption>\n",
    "</figure>    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_pdfs(z1_w, Wz1_w, z2_w, Wz2_w):\n",
    "    \"\"\" Method to combine the pdfs associated with two observations of the same landmark.  \n",
    "        \n",
    "        Args:            \n",
    "            z1_w: Landmark observed in cartesian coordinates(world frame) from Robot 1\n",
    "            Wz1_w: Covariance associated to the landmark.\n",
    "            z1_w: Landmark observed in cartesian coordinates(world frame) from Robot 2\n",
    "            Wz2_w: Covariance associated to the landmark.\n",
    "        Returns:\n",
    "            z: Combined observation\n",
    "            W_z: Uncertainty associated to z\n",
    "    \"\"\"\n",
    "    None # Implement the needed code here\n",
    "\n",
    "    W_z = None\n",
    "    z = None\n",
    "\n",
    "    return z, W_z\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z2_p_r = np.vstack([4., .3])\n",
    "Wz2_p_r = np.diag([0.25, 0.04])\n",
    "\n",
    "z1_w, Qz1 = to_world_frame(p1_w, Qp1_w, z1_p_r, W1)\n",
    "z2_w, Qz2 = to_world_frame(p2_w, Qp2_w, z2_p_r, W1)\n",
    "\n",
    "# Show results\n",
    "fig, ax = plt.subplots()\n",
    "plt.xlim([-.5, 10])\n",
    "plt.ylim([-.5, 10])\n",
    "plt.grid()\n",
    "plt.tight_layout()\n",
    "\n",
    "fig.canvas.draw()\n",
    "\n",
    "DrawRobot(fig, ax, p1_w, label='R1', color='blue')\n",
    "PlotEllipse(fig, ax, p1_w, Qp1_w, color='blue')\n",
    "\n",
    "DrawRobot(fig, ax, p2_w, label='R2', color='green')\n",
    "PlotEllipse(fig, ax, p2_w, Qp2_w, color='green')\n",
    "   \n",
    "ax.plot(z1_w[0, 0], z1_w[1, 0], 'o', label='Z1', color='blue')\n",
    "PlotEllipse(fig, ax, z1_w, Qz1, color='blue')\n",
    "          \n",
    "ax.plot(z2_w[0, 0], z2_w[1, 0], 'o', label='Z2', color='green')\n",
    "PlotEllipse(fig, ax, z2_w, Qz2, color='green')\n",
    "\n",
    "z_w, Wz_w = combine_pdfs(z1_w, Qz1, z2_w, Qz2)\n",
    "ax.plot(z_w[0, 0], z_w[1, 0], 'o', label='Z3', color='red')\n",
    "PlotEllipse(fig, ax, z_w, Wz_w, color='red')\n",
    "          \n",
    "plt.legend()\n",
    "\n",
    "# Print results\n",
    "print( '----\\tExercise 4.1.5\\t----\\n'+\n",
    "    'z2_w = {}\\'\\n'.format(z2_w.flatten())+\n",
    "    'Qz2 = \\n{}\\n'.format(Qz2)\n",
    "    )\n",
    "\n",
    "# Print results\n",
    "print( '----\\tExercise 4.1.5 parte 2\\t----\\n'+\n",
    "    'z_w = {}\\'\\n'.format(z_w.flatten())+\n",
    "    'Wz_w = \\n{}\\n'.format(Wz_w)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">Expected ouputs:</span>\n",
    "\n",
    "### Sensor measurement from R2\n",
    "\n",
    "```\n",
    "z2_w = [3.05042514 6.70185272]'\n",
    "Qz2 = \n",
    "[[0.84693794 0.4333316 ]\n",
    " [0.4333316  0.81306206]]\n",
    "```\n",
    "\n",
    "### Combined information\n",
    "```\n",
    "---- Exercise 4.1.5 parte 2 ----\n",
    "z_w = [2.58757252 6.15534036]'\n",
    "Wz_w = \n",
    "[[0.37966125 0.07773125]\n",
    " [0.07773125 0.36999739]]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:green\">OPTIONAL</span>\n",
    "\n",
    "<span style=\"color:green\">An alternative to *landmark observation models* are *scan observation* ones, which work with scan-based sensors. Below, the three most popular ones are listed. Surf the internet for some code illustrating any of them, and include it in the notebook with a brief description of how it works and its purpose.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.2 Scan observation models\n",
    "\n",
    "Scan observation models are used when the sensor mounted on the robot provides a scan measuring distance and angle to obstacles in the workspace, *e.g.* a laser range finder. In this case, each element in the map is a cell described by its position (and probably a color representing if its free of obstacles or occupied), and data association is not explicitly addressed. \n",
    "\n",
    "#### Beam model\n",
    "#### Likelihood field\n",
    "#### Scan matching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:green\">***END OF OPTIONAL PART***</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Student discussion\n",
    "In the cell below, discuss what has been done in the notebook, what you have found interesting, or any other relevant thought."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:orangered\">***Write your answer here***</span>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
